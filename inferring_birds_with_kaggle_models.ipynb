{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ctrivino1/BirdAudio/blob/main/inferring_birds_with_kaggle_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we'll use a pre-trained machine learning model to generate a submission to the [BirdClef2023 competition](https://www.kaggle.com/c/birdclef-2023).  The goal of the competition is to identify Eastern African bird species by sound."
      ],
      "metadata": {
        "id": "Bt5AsiTneRR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_io "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCjhm3RGfvVa",
        "outputId": "aae73174-749d-45b7-f688-36ebc04a207f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.31.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.31.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io) (0.31.0)\n",
            "Installing collected packages: tensorflow_io\n",
            "Successfully installed tensorflow_io-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Imports"
      ],
      "metadata": {
        "id": "hh-prYsFeRR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_io as tfio\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "\n",
        "import csv\n",
        "import io\n",
        "\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-03-07T18:26:05.893236Z",
          "iopub.execute_input": "2023-03-07T18:26:05.893687Z",
          "iopub.status.idle": "2023-03-07T18:26:15.443097Z",
          "shell.execute_reply.started": "2023-03-07T18:26:05.89362Z",
          "shell.execute_reply": "2023-03-07T18:26:15.441763Z"
        },
        "trusted": true,
        "id": "c-onaRLeeRSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Explore the training data\n",
        "\n",
        "We'll start by loading a couple of training examples and using the IPython.display.Audio module to play them!"
      ],
      "metadata": {
        "id": "m31Fhfd3eRSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a sample audio files from two different species\n",
        "audio_abe, sr_abe = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/abethr1/XC128013.ogg\")\n",
        "audio_abh, sr_abh = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/abhori1/XC127317.ogg\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:26:15.44478Z",
          "iopub.execute_input": "2023-03-07T18:26:15.445668Z",
          "iopub.status.idle": "2023-03-07T18:26:25.821183Z",
          "shell.execute_reply.started": "2023-03-07T18:26:15.445601Z",
          "shell.execute_reply": "2023-03-07T18:26:25.819673Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "x3iqUWFjeRSM",
        "outputId": "cf64b382-e1cc-4730-ebbc-f7e478fb1652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    657\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error opening {0!r}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/kaggle/input/birdclef-2023/train_audio/abethr1/XC128013.ogg': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4fd1b0e24f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load a sample audio files from two different species\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maudio_abe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_abe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/birdclef-2023/train_audio/abethr1/XC128013.ogg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maudio_abh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_abh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/birdclef-2023/train_audio/abhori1/XC127317.ogg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPurePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/birdclef-2023/train_audio/abethr1/XC128013.ogg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the audio\n",
        "Audio(data=audio_abe, rate=sr_abe)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:26:25.822527Z",
          "iopub.execute_input": "2023-03-07T18:26:25.823301Z",
          "iopub.status.idle": "2023-03-07T18:26:25.873528Z",
          "shell.execute_reply.started": "2023-03-07T18:26:25.823267Z",
          "shell.execute_reply": "2023-03-07T18:26:25.872446Z"
        },
        "trusted": true,
        "id": "mfofL7J1eRSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the audio\n",
        "Audio(data=audio_abh, rate=sr_abh)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:26:25.874393Z",
          "iopub.execute_input": "2023-03-07T18:26:25.874881Z",
          "iopub.status.idle": "2023-03-07T18:26:25.915097Z",
          "shell.execute_reply.started": "2023-03-07T18:26:25.874851Z",
          "shell.execute_reply": "2023-03-07T18:26:25.914013Z"
        },
        "trusted": true,
        "id": "xUEJFeELeRSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Match the model's output with the bird species in the competition\n",
        "\n",
        "The competition includes 264 classes of birds, 261 of which exist in this model. We'll set up a way to map the model's output logits to our competition."
      ],
      "metadata": {
        "id": "5LlrTBnVeRSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = hub.load('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/tensorFlow2/variations/bird-vocalization-classifier/versions/1')\n",
        "labels_path = hub.resolve('https://kaggle.com/models/google/bird-vocalization-classifier/frameworks/tensorFlow2/variations/bird-vocalization-classifier/versions/1') + \"/assets/label.csv\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:26:25.918763Z",
          "iopub.execute_input": "2023-03-07T18:26:25.919053Z",
          "iopub.status.idle": "2023-03-07T18:26:33.264685Z",
          "shell.execute_reply.started": "2023-03-07T18:26:25.919023Z",
          "shell.execute_reply": "2023-03-07T18:26:33.263005Z"
        },
        "trusted": true,
        "id": "KaLLOPT3eRSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the name of the class with the top score when mean-aggregated across frames.\n",
        "def class_names_from_csv(class_map_csv_text):\n",
        "    \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
        "    with open(labels_path) as csv_file:\n",
        "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "        class_names = [mid for mid, desc in csv_reader]\n",
        "        return class_names[1:]\n",
        "\n",
        "## note that the bird classifier classifies a much larger set of birds than the\n",
        "## competition, so we need to load the model's set of class names or else our \n",
        "## indices will be off.\n",
        "classes = class_names_from_csv(labels_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:26:33.266455Z",
          "iopub.execute_input": "2023-03-07T18:26:33.266825Z",
          "iopub.status.idle": "2023-03-07T18:26:33.290684Z",
          "shell.execute_reply.started": "2023-03-07T18:26:33.266789Z",
          "shell.execute_reply": "2023-03-07T18:26:33.289205Z"
        },
        "trusted": true,
        "id": "fWlH8ZyteRSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_metadata = pd.read_csv(\"/kaggle/input/birdclef-2023/train_metadata.csv\")\n",
        "train_metadata.head()\n",
        "competition_classes = sorted(train_metadata.primary_label.unique())\n",
        "\n",
        "forced_defaults = 0\n",
        "competition_class_map = []\n",
        "for c in competition_classes:\n",
        "    try:\n",
        "        i = classes.index(c)\n",
        "        competition_class_map.append(i)\n",
        "    except:\n",
        "        competition_class_map.append(0)\n",
        "        forced_defaults += 1\n",
        "        \n",
        "## this is the count of classes not supported by our pretrained model\n",
        "## you could choose to simply not predict these, set a default as above,\n",
        "## or create your own model using the pretrained model as a base.\n",
        "forced_defaults"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:26:33.292249Z",
          "iopub.execute_input": "2023-03-07T18:26:33.292678Z",
          "iopub.status.idle": "2023-03-07T18:26:33.458124Z",
          "shell.execute_reply.started": "2023-03-07T18:26:33.292611Z",
          "shell.execute_reply": "2023-03-07T18:26:33.457Z"
        },
        "trusted": true,
        "id": "GX2bFnwoeRSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Preprocess the data\n",
        "\n",
        "The following functions are one way to load the audio provided and break it up into the five-second samples with a sample rate of 32,000 required by the competition."
      ],
      "metadata": {
        "id": "uNzwxFe1eRSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frame_audio(\n",
        "      audio_array: np.ndarray,\n",
        "      window_size_s: float = 5.0,\n",
        "      hop_size_s: float = 5.0,\n",
        "      sample_rate = 32000,\n",
        "      ) -> np.ndarray:\n",
        "    \n",
        "    \"\"\"Helper function for framing audio for inference.\"\"\"\n",
        "    \"\"\" using tf.signal \"\"\"\n",
        "    if window_size_s is None or window_size_s < 0:\n",
        "        return audio_array[np.newaxis, :]\n",
        "    frame_length = int(window_size_s * sample_rate)\n",
        "    hop_length = int(hop_size_s * sample_rate)\n",
        "    framed_audio = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=True)\n",
        "    return framed_audio\n",
        "\n",
        "def ensure_sample_rate(waveform, original_sample_rate,\n",
        "                       desired_sample_rate=32000):\n",
        "    \"\"\"Resample waveform if required.\"\"\"\n",
        "    if original_sample_rate != desired_sample_rate:\n",
        "        waveform = tfio.audio.resample(waveform, original_sample_rate, desired_sample_rate)\n",
        "    return desired_sample_rate, waveform"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:26:33.459554Z",
          "iopub.execute_input": "2023-03-07T18:26:33.45989Z",
          "iopub.status.idle": "2023-03-07T18:26:33.469971Z",
          "shell.execute_reply.started": "2023-03-07T18:26:33.459858Z",
          "shell.execute_reply": "2023-03-07T18:26:33.46833Z"
        },
        "trusted": true,
        "id": "eb2M6-HgeRSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we load one training sample - use the Audio function to listen to the samples inside the notebook!"
      ],
      "metadata": {
        "id": "1vbYUsCmeRSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio, sample_rate = librosa.load(\"/kaggle/input/birdclef-2023/train_audio/afghor1/XC156639.ogg\")\n",
        "sample_rate, wav_data = ensure_sample_rate(audio, sample_rate)\n",
        "Audio(wav_data, rate=sample_rate)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:26:33.474189Z",
          "iopub.execute_input": "2023-03-07T18:26:33.474536Z",
          "iopub.status.idle": "2023-03-07T18:26:34.056941Z",
          "shell.execute_reply.started": "2023-03-07T18:26:33.474501Z",
          "shell.execute_reply": "2023-03-07T18:26:34.055418Z"
        },
        "trusted": true,
        "id": "zWeC9GYzeRSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Make predictions\n",
        "\n",
        "Each test sample is cut into 5-second chunks. We use the pretrained model to return probabilities for all 10k birds included in the model, then pull out the classes used in this competition to create a final submission row. Note that we are NOT doing anything special to handle the 3 missing classes; those will need fine-tuning / transfer learning, which will be handled in a separate notebook."
      ],
      "metadata": {
        "id": "W0U39mDHeRSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_tm = frame_audio(wav_data)\n",
        "logits, embeddings = model.infer_tf(fixed_tm[:1])\n",
        "probabilities = tf.nn.softmax(logits)\n",
        "argmax = np.argmax(probabilities)\n",
        "print(f\"The audio is from the class {classes[argmax]} (element:{argmax} in the label.csv file), with probability of {probabilities[0][argmax]}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:27:33.85177Z",
          "iopub.execute_input": "2023-03-07T18:27:33.852139Z",
          "iopub.status.idle": "2023-03-07T18:27:42.452689Z",
          "shell.execute_reply.started": "2023-03-07T18:27:33.852108Z",
          "shell.execute_reply": "2023-03-07T18:27:42.451217Z"
        },
        "trusted": true,
        "id": "ILkLBbUkeRSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_for_sample(filename, sample_submission, frame_limit_secs=None):\n",
        "    file_id = filename.split(\".ogg\")[0].split(\"/\")[-1]\n",
        "    \n",
        "    audio, sample_rate = librosa.load(filename)\n",
        "    sample_rate, wav_data = ensure_sample_rate(audio, sample_rate)\n",
        "    \n",
        "    fixed_tm = frame_audio(wav_data)\n",
        "    \n",
        "    frame = 5\n",
        "    all_logits, all_embeddings = model.infer_tf(fixed_tm[:1])\n",
        "    for window in fixed_tm[1:]:\n",
        "        if frame_limit_secs and frame > frame_limit_secs:\n",
        "            continue\n",
        "        \n",
        "        logits, embeddings = model.infer_tf(window[np.newaxis, :])\n",
        "        all_logits = np.concatenate([all_logits, logits], axis=0)\n",
        "        frame += 5\n",
        "    \n",
        "    frame = 5\n",
        "    all_probabilities = []\n",
        "    for frame_logits in all_logits:\n",
        "        probabilities = tf.nn.softmax(frame_logits).numpy()\n",
        "        \n",
        "        ## set the appropriate row in the sample submission\n",
        "        sample_submission.loc[sample_submission.row_id == file_id + \"_\" + str(frame), competition_classes] = probabilities[competition_class_map]\n",
        "        frame += 5"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:27:42.456508Z",
          "iopub.execute_input": "2023-03-07T18:27:42.456847Z",
          "iopub.status.idle": "2023-03-07T18:27:42.466058Z",
          "shell.execute_reply.started": "2023-03-07T18:27:42.456815Z",
          "shell.execute_reply": "2023-03-07T18:27:42.464463Z"
        },
        "trusted": true,
        "id": "4Ny4m5r2eRSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Generate a submission\n",
        "\n",
        "Now we process all of the test samples as discussed above, creating output rows, and saving them in the provided `sample_submission.csv`. Finally, we save these rows to our final output file: `submission.csv`. This is the file that gets submitted and scored when you submit the notebook."
      ],
      "metadata": {
        "id": "tKgUJKZneRSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = list(glob.glob(\"/kaggle/input/birdclef-2023/test_soundscapes/*.ogg\"))\n",
        "test_samples"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:27:42.46746Z",
          "iopub.execute_input": "2023-03-07T18:27:42.468572Z",
          "iopub.status.idle": "2023-03-07T18:27:42.491495Z",
          "shell.execute_reply.started": "2023-03-07T18:27:42.46851Z",
          "shell.execute_reply": "2023-03-07T18:27:42.49023Z"
        },
        "trusted": true,
        "id": "lRlOjDIheRSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub = pd.read_csv(\"/kaggle/input/birdclef-2023/sample_submission.csv\")\n",
        "sample_sub[competition_classes] = sample_sub[competition_classes].astype(np.float32)\n",
        "sample_sub.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:27:42.493996Z",
          "iopub.execute_input": "2023-03-07T18:27:42.494288Z",
          "iopub.status.idle": "2023-03-07T18:27:42.598852Z",
          "shell.execute_reply.started": "2023-03-07T18:27:42.494253Z",
          "shell.execute_reply": "2023-03-07T18:27:42.597816Z"
        },
        "trusted": true,
        "id": "q8xdtOyfeRSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_limit_secs = 15 if sample_sub.shape[0] == 3 else None\n",
        "for sample_filename in test_samples:\n",
        "    predict_for_sample(sample_filename, sample_sub, frame_limit_secs=15)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:27:42.600544Z",
          "iopub.execute_input": "2023-03-07T18:27:42.600888Z",
          "iopub.status.idle": "2023-03-07T18:27:48.722475Z",
          "shell.execute_reply.started": "2023-03-07T18:27:42.600855Z",
          "shell.execute_reply": "2023-03-07T18:27:48.720492Z"
        },
        "trusted": true,
        "id": "aaqTU1W3eRSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:27:48.723696Z",
          "iopub.execute_input": "2023-03-07T18:27:48.724021Z",
          "iopub.status.idle": "2023-03-07T18:27:48.753783Z",
          "shell.execute_reply.started": "2023-03-07T18:27:48.723987Z",
          "shell.execute_reply": "2023-03-07T18:27:48.752703Z"
        },
        "trusted": true,
        "id": "0c_cVxH1eRSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sub.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-07T18:27:48.755372Z",
          "iopub.execute_input": "2023-03-07T18:27:48.755961Z",
          "iopub.status.idle": "2023-03-07T18:27:48.77547Z",
          "shell.execute_reply.started": "2023-03-07T18:27:48.755926Z",
          "shell.execute_reply": "2023-03-07T18:27:48.774069Z"
        },
        "trusted": true,
        "id": "aRNjLDsUeRSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tIE9sDkYeRSy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}